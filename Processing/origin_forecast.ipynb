{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "# Suppress logs from cmdstanpy\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
    "\n",
    "# Suppress logs from prophet\n",
    "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
    "\n",
    "# Optionally, suppress other libraries if they are also too verbose\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('seaborn').setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "# Import the flight_forecasting module\n",
    "import flight_forecasting as ff\n",
    "\n",
    "# For displaying plots within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Optional: Set Seaborn style for better aesthetics\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight Data Import\n",
    "List all the CSV filenames corresponding to different origin airports. Ensure that these files are present in the `INPUT_DIR` specified in `flight_forecasting.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV filenames corresponding to different origin airports\n",
    "CSV_FILES = [\n",
    "    'Origin Airport Baltimore, MD BaltimoreWashington International Thurgood Marshall (BWI).csv',\n",
    "    'Origin Airport Chicago, IL Chicago Midway International (MDW).csv',\n",
    "    'Origin Airport Dallas, TX Dallas Love Field (DAL).csv',\n",
    "    'Origin Airport Denver, CO Denver International (DEN).csv',\n",
    "    'Origin Airport Las Vegas, NV Harry Reid International (LAS).csv'\n",
    "]\n",
    "\n",
    "# Update the flight_forecasting module's CSV_FILES if necessary\n",
    "ff.CSV_FILES = CSV_FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and Forecasting\n",
    "\n",
    "- Load each CSV file, clean the data by handling missing values, and filter for the specified month (June by default).\n",
    "- Aggregate the number of flights per year for the specified month.\n",
    "- Iterate through each CSV file, perform forecasting using various models, evaluate their performance, and visualize the results.\n",
    "  - Forecasting Models tested:\n",
    "    - ARIMA\n",
    "    - Exponential Smoothing\n",
    "    - Linear Regression\n",
    "    - Naive Forecast\n",
    "    - Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing Airport: Baltimore, MD BaltimoreWashington International Thurgood Marshall (BWI)\n",
      "================================================================================\n",
      "Loaded data from D:/GitHub Repos/630-SOUTHWEST-SCHEDULING/Data/Origin Airport Baltimore, MD BaltimoreWashington International Thurgood Marshall (BWI).csv successfully.\n",
      "\n",
      "First few rows of the cleaned DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Carrier Code</th>\n",
       "      <th>Date (MM/DD/YYYY)</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Tail Number</th>\n",
       "      <th>Destination Airport</th>\n",
       "      <th>Scheduled departure time</th>\n",
       "      <th>Actual departure time</th>\n",
       "      <th>Scheduled elapsed time (Minutes)</th>\n",
       "      <th>Actual elapsed time (Minutes)</th>\n",
       "      <th>Departure delay (Minutes)</th>\n",
       "      <th>Wheels-off time</th>\n",
       "      <th>Taxi-Out time (Minutes)</th>\n",
       "      <th>Delay Carrier (Minutes)</th>\n",
       "      <th>Delay Weather (Minutes)</th>\n",
       "      <th>Delay National Aviation System (Minutes)</th>\n",
       "      <th>Delay Security (Minutes)</th>\n",
       "      <th>Delay Late Aircraft Arrival (Minutes)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WN</td>\n",
       "      <td>6/1/2003</td>\n",
       "      <td>85.0</td>\n",
       "      <td>N431</td>\n",
       "      <td>LAX</td>\n",
       "      <td>17:45</td>\n",
       "      <td>17:50</td>\n",
       "      <td>380.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WN</td>\n",
       "      <td>6/1/2003</td>\n",
       "      <td>846.0</td>\n",
       "      <td>N410</td>\n",
       "      <td>LAX</td>\n",
       "      <td>9:40</td>\n",
       "      <td>10:00</td>\n",
       "      <td>380.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10:07</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WN</td>\n",
       "      <td>6/1/2004</td>\n",
       "      <td>85.0</td>\n",
       "      <td>N438</td>\n",
       "      <td>LAX</td>\n",
       "      <td>17:50</td>\n",
       "      <td>19:33</td>\n",
       "      <td>355.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>19:43</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2004-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WN</td>\n",
       "      <td>6/1/2004</td>\n",
       "      <td>285.0</td>\n",
       "      <td>N709SW</td>\n",
       "      <td>SAN</td>\n",
       "      <td>19:10</td>\n",
       "      <td>20:35</td>\n",
       "      <td>355.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>20:44</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2004-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WN</td>\n",
       "      <td>6/1/2004</td>\n",
       "      <td>590.0</td>\n",
       "      <td>N453</td>\n",
       "      <td>SAN</td>\n",
       "      <td>11:05</td>\n",
       "      <td>11:05</td>\n",
       "      <td>355.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11:18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Carrier Code Date (MM/DD/YYYY)  Flight Number Tail Number  \\\n",
       "0           WN          6/1/2003           85.0        N431   \n",
       "1           WN          6/1/2003          846.0        N410   \n",
       "2           WN          6/1/2004           85.0        N438   \n",
       "3           WN          6/1/2004          285.0      N709SW   \n",
       "4           WN          6/1/2004          590.0        N453   \n",
       "\n",
       "  Destination Airport Scheduled departure time Actual departure time  \\\n",
       "0                 LAX                    17:45                 17:50   \n",
       "1                 LAX                     9:40                 10:00   \n",
       "2                 LAX                    17:50                 19:33   \n",
       "3                 SAN                    19:10                 20:35   \n",
       "4                 SAN                    11:05                 11:05   \n",
       "\n",
       "   Scheduled elapsed time (Minutes)  Actual elapsed time (Minutes)  \\\n",
       "0                             380.0                          325.0   \n",
       "1                             380.0                          315.0   \n",
       "2                             355.0                          325.0   \n",
       "3                             355.0                          315.0   \n",
       "4                             355.0                          335.0   \n",
       "\n",
       "   Departure delay (Minutes) Wheels-off time  Taxi-Out time (Minutes)  \\\n",
       "0                        5.0           18:00                     10.0   \n",
       "1                       20.0           10:07                      7.0   \n",
       "2                      103.0           19:43                     10.0   \n",
       "3                       85.0           20:44                      9.0   \n",
       "4                        0.0           11:18                     13.0   \n",
       "\n",
       "   Delay Carrier (Minutes)  Delay Weather (Minutes)  \\\n",
       "0                      0.0                      0.0   \n",
       "1                      0.0                      0.0   \n",
       "2                      9.0                      0.0   \n",
       "3                      3.0                      0.0   \n",
       "4                      0.0                      0.0   \n",
       "\n",
       "   Delay National Aviation System (Minutes)  Delay Security (Minutes)  \\\n",
       "0                                       0.0                       0.0   \n",
       "1                                       0.0                       0.0   \n",
       "2                                       0.0                       0.0   \n",
       "3                                       0.0                       0.0   \n",
       "4                                       0.0                       0.0   \n",
       "\n",
       "   Delay Late Aircraft Arrival (Minutes)       Date  Month  Year  \n",
       "0                                    0.0 2003-06-01      6  2003  \n",
       "1                                    0.0 2003-06-01      6  2003  \n",
       "2                                   64.0 2004-06-01      6  2004  \n",
       "3                                   42.0 2004-06-01      6  2004  \n",
       "4                                    0.0 2004-06-01      6  2004  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Flights Per Year (June only):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Destination Airport</th>\n",
       "      <th>Number_of_Flights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>LAX</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>LAX</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2024</td>\n",
       "      <td>CHS</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2024</td>\n",
       "      <td>LAX</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2024</td>\n",
       "      <td>MIA</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2024</td>\n",
       "      <td>SAN</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2024</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year Destination Airport  Number_of_Flights\n",
       "0   2000                 NaN                  0\n",
       "1   2001                 NaN                  0\n",
       "2   2002                 NaN                  0\n",
       "3   2003                 LAX                 60\n",
       "4   2004                 LAX                 62\n",
       "..   ...                 ...                ...\n",
       "87  2024                 CHS                107\n",
       "88  2024                 LAX                 84\n",
       "89  2024                 MIA                 97\n",
       "90  2024                 SAN                 83\n",
       "91  2024                 SEA                  4\n",
       "\n",
       "[92 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Year: 2001\n",
      "Exponential Smoothing failed for year 2001: index 1 is out of bounds for axis 0 with size 1\n",
      "Prophet model failed for year 2001: Dataframe has less than 2 non-NaN rows.\n",
      "\n",
      "Processing Year: 2002\n",
      "ARIMA model failed for year 2002: too many indices for array: array is 0-dimensional, but 1 were indexed\n",
      "\n",
      "Processing Year: 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:58:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:58:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Year: 2004\n",
      "\n",
      "Processing Year: 2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:58:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:58:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:58:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:58:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Year: 2005\n",
      "\n",
      "Processing Year: 2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:58:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:58:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:58:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:58:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Year: 2006\n",
      "\n",
      "Processing Year: 2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:58:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:58:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m display(flights_per_year)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Perform walk-forward validation\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m results \u001b[38;5;241m=\u001b[39m ff\u001b[38;5;241m.\u001b[39mwalk_forward_validation(flights_per_year)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Display forecasting results\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecasting Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\GitHub Repos\\630-SOUTHWEST-SCHEDULING\\Processing\\flight_forecasting.py:350\u001b[0m, in \u001b[0;36mwalk_forward_validation\u001b[1;34m(flights_per_year)\u001b[0m\n\u001b[0;32m    338\u001b[0m results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m: test_year,\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExponential Smoothing\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: rmse_hw\n\u001b[0;32m    345\u001b[0m }, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;66;03m# 5. Facebook Prophet\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m predicted_prophet \u001b[38;5;241m=\u001b[39m forecast_prophet(train_data, test_year)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(predicted_prophet):\n\u001b[0;32m    352\u001b[0m     mae_prophet \u001b[38;5;241m=\u001b[39m mean_absolute_error([actual_flights], [predicted_prophet])\n",
      "File \u001b[1;32md:\\GitHub Repos\\630-SOUTHWEST-SCHEDULING\\Processing\\flight_forecasting.py:249\u001b[0m, in \u001b[0;36mforecast_prophet\u001b[1;34m(train_data, test_year)\u001b[0m\n\u001b[0;32m    246\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(prophet_train)\n\u001b[0;32m    248\u001b[0m future \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m: [pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-06-01\u001b[39m\u001b[38;5;124m'\u001b[39m)]})\n\u001b[1;32m--> 249\u001b[0m forecast \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(future)\n\u001b[0;32m    250\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(forecast[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myhat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1275\u001b[0m, in \u001b[0;36mProphet.predict\u001b[1;34m(self, df, vectorized)\u001b[0m\n\u001b[0;32m   1273\u001b[0m seasonal_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_seasonal_components(df)\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty_samples:\n\u001b[1;32m-> 1275\u001b[0m     intervals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_uncertainty(df, vectorized)\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     intervals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1440\u001b[0m, in \u001b[0;36mProphet.predict_uncertainty\u001b[1;34m(self, df, vectorized)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_uncertainty\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pd\u001b[38;5;241m.\u001b[39mDataFrame, vectorized: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prediction intervals for yhat and trend.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m \n\u001b[0;32m   1431\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;124;03m    Dataframe with uncertainty intervals.\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1440\u001b[0m     sim_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_posterior_predictive(df, vectorized)\n\u001b[0;32m   1442\u001b[0m     lower_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterval_width) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   1443\u001b[0m     upper_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterval_width) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1473\u001b[0m, in \u001b[0;36mProphet.sample_posterior_predictive\u001b[1;34m(self, df, vectorized)\u001b[0m\n\u001b[0;32m   1468\u001b[0m samp_per_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty_samples \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(n_iterations)\n\u001b[0;32m   1470\u001b[0m )))\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;66;03m# Generate seasonality features once so we can re-use them.\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m seasonal_features, _, component_cols, _ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_all_seasonality_features(df)\n\u001b[0;32m   1474\u001b[0m )\n\u001b[0;32m   1475\u001b[0m sim_values \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myhat\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrend\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:846\u001b[0m, in \u001b[0;36mProphet.make_all_seasonality_features\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    843\u001b[0m     prior_scales\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m    845\u001b[0m seasonal_features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(seasonal_features, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 846\u001b[0m component_cols, modes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregressor_column_matrix(\n\u001b[0;32m    847\u001b[0m     seasonal_features, modes\n\u001b[0;32m    848\u001b[0m )\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seasonal_features, prior_scales, component_cols, modes\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:890\u001b[0m, in \u001b[0;36mProphet.regressor_column_matrix\u001b[1;34m(self, seasonal_features, modes)\u001b[0m\n\u001b[0;32m    883\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_group_component(\n\u001b[0;32m    884\u001b[0m     components, mode \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_terms\u001b[39m\u001b[38;5;124m'\u001b[39m, modes[mode]\n\u001b[0;32m    885\u001b[0m )\n\u001b[0;32m    886\u001b[0m regressors_by_mode \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    887\u001b[0m     r \u001b[38;5;28;01mfor\u001b[39;00m r, props \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_regressors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m props[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m mode\n\u001b[0;32m    889\u001b[0m ]\n\u001b[1;32m--> 890\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_group_component(\n\u001b[0;32m    891\u001b[0m     components, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextra_regressors_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mode, regressors_by_mode)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# Add combination components to modes\u001b[39;00m\n\u001b[0;32m    893\u001b[0m modes[mode]\u001b[38;5;241m.\u001b[39mappend(mode \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_terms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:932\u001b[0m, in \u001b[0;36mProphet.add_group_component\u001b[1;34m(self, components, name, group)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_group_component\u001b[39m(\u001b[38;5;28mself\u001b[39m, components, name, group):\n\u001b[0;32m    919\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Adds a component with given name that contains all of the components\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m    in group.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;124;03m    Dataframe with components.\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m     new_comp \u001b[38;5;241m=\u001b[39m components[components[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomponent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mset\u001b[39m(group))]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    933\u001b[0m     group_cols \u001b[38;5;241m=\u001b[39m new_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(group_cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3798\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3796\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_bool_array(key)\n\u001b[0;32m   3800\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3853\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3851\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[0;32m   3852\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 3853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3896\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3900\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3901\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3902\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   3903\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3886\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3879\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3880\u001b[0m \u001b[38;5;124;03mInternal version of the `take` allowing specification of additional args.\u001b[39;00m\n\u001b[0;32m   3881\u001b[0m \n\u001b[0;32m   3882\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3883\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m-> 3886\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   3887\u001b[0m     indices,\n\u001b[0;32m   3888\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   3889\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3890\u001b[0m     convert_indices\u001b[38;5;241m=\u001b[39mconvert_indices,\n\u001b[0;32m   3891\u001b[0m )\n\u001b[0;32m   3892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:978\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    975\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    977\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    979\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[0;32m    980\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m    981\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    982\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    983\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:770\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    767\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(new_blocks, new_axes, new_refs, parent\u001b[38;5;241m=\u001b[39mparent)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;66;03m# We can avoid the need to rebuild these\u001b[39;00m\n\u001b[1;32m--> 770\u001b[0m     new_mgr\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    771\u001b[0m     new_mgr\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgr\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize a list to store predictions for 2025\n",
    "prediction_summary = []\n",
    "\n",
    "# Iterate through each CSV file and perform forecasting\n",
    "for csv_file in ff.CSV_FILES:\n",
    "    # Extract airport name from the filename\n",
    "    airport_name = csv_file.split('.csv')[0].replace('Origin Airport ', '').strip()\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\nProcessing Airport: {airport_name}\\n{'='*80}\")\n",
    "    \n",
    "    # Load data\n",
    "    filepath = os.path.join(ff.INPUT_DIR, csv_file)\n",
    "    df_raw = ff.load_data(filepath)\n",
    "    if df_raw is None:\n",
    "        print(f\"Skipping {airport_name} due to loading issues.\")\n",
    "        continue  # Skip to the next file if loading failed\n",
    "    \n",
    "    # Clean and prepare data\n",
    "    df_clean = ff.clean_and_prepare_data(df_raw, month=ff.FORECAST_MONTH)\n",
    "    \n",
    "    # Display first few rows of cleaned data\n",
    "    print(\"\\nFirst few rows of the cleaned DataFrame:\")\n",
    "    display(df_clean.head())\n",
    "    \n",
    "    # Aggregate flights per year\n",
    "    flights_per_year = ff.aggregate_flights(df_clean)\n",
    "    \n",
    "    # Ensure complete years from 2000 to 2024\n",
    "    all_years = pd.DataFrame({'Year': range(2000, 2025)})\n",
    "    flights_per_year = pd.merge(all_years, flights_per_year, on='Year', how='left')\n",
    "    flights_per_year['Number_of_Flights'] = flights_per_year['Number_of_Flights'].fillna(0).astype(int)\n",
    "    \n",
    "    print(\"\\nComplete Flights Per Year (June only):\")\n",
    "    display(flights_per_year)\n",
    "    \n",
    "    # Perform walk-forward validation\n",
    "    results = ff.walk_forward_validation(flights_per_year)\n",
    "    \n",
    "    # Display forecasting results\n",
    "    print(\"\\nForecasting Results:\")\n",
    "    display(results)\n",
    "    \n",
    "    # Calculate performance summary\n",
    "    results_clean = results.dropna()\n",
    "    performance_summary = results_clean.groupby('Model').agg({\n",
    "        'MAE': 'mean',\n",
    "        'RMSE': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    display(performance_summary)\n",
    "    \n",
    "    # Identify the best model based on RMSE\n",
    "    best_model_row = performance_summary.loc[performance_summary['RMSE'].idxmin()]\n",
    "    best_model = best_model_row['Model']\n",
    "    best_rmse = best_model_row['RMSE']\n",
    "    \n",
    "    print(f\"\\nBest Model for {airport_name}: {best_model} with RMSE = {best_rmse:.2f}\")\n",
    "    \n",
    "    # Forecasting for 2025 Using the Best Model\n",
    "    print(f\"\\nForecasting 2025 for {airport_name} using {best_model}...\\n\")\n",
    "    \n",
    "    # Prepare data for forecasting 2025\n",
    "    # Create a DataFrame for training up to 2024\n",
    "    train_data_2025 = flights_per_year.copy()\n",
    "    \n",
    "    # Depending on the model, fit and forecast accordingly\n",
    "    if best_model == 'Naïve Forecast':\n",
    "        # For Naïve Forecast, prediction is the last known value\n",
    "        prediction_2025 = ff.forecast_naive(train_data_2025)\n",
    "    elif best_model == 'Linear Regression':\n",
    "        prediction_2025 = ff.forecast_linear_regression(train_data_2025, test_year=2025)\n",
    "    elif best_model == 'ARIMA(1,1,1)':\n",
    "        prediction_2025 = ff.forecast_arima(train_data_2025, test_year=2025)\n",
    "    elif best_model == 'Exponential Smoothing':\n",
    "        prediction_2025 = ff.forecast_exponential_smoothing(train_data_2025, test_year=2025)\n",
    "    elif best_model == 'Prophet':\n",
    "        prediction_2025 = ff.forecast_prophet(train_data_2025, test_year=2025)\n",
    "    else:\n",
    "        print(f\"Unknown model: {best_model}. Cannot forecast 2025.\")\n",
    "        prediction_2025 = np.nan\n",
    "    \n",
    "    # Handle cases where prediction could not be made\n",
    "    if np.isnan(prediction_2025):\n",
    "        print(f\"Prediction for 2025 could not be made using {best_model}.\")\n",
    "        prediction_2025_display = \"Prediction Failed\"\n",
    "    else:\n",
    "        prediction_2025_display = int(prediction_2025)\n",
    "    \n",
    "    # Append the prediction to the summary table\n",
    "    prediction_summary.append({\n",
    "        'Airport': airport_name,\n",
    "        '2025 Predicted Flights': prediction_2025_display,\n",
    "        'Model Used': best_model\n",
    "    })\n",
    "    \n",
    "    print(f\"2025 Predicted Flights for {airport_name}: {prediction_2025_display}\")\n",
    "    \n",
    "    # Save forecasting results\n",
    "    ff.save_forecasts(results, ff.OUTPUT_DIR, airport_name)\n",
    "    \n",
    "    # Save performance summary\n",
    "    airport_output_dir = os.path.join(ff.OUTPUT_DIR, airport_name)\n",
    "    performance_summary_path = os.path.join(airport_output_dir, f'{airport_name}_Performance_Summary.csv')\n",
    "    performance_summary.to_csv(performance_summary_path, index=False)\n",
    "    print(f\"Performance summary saved to {performance_summary_path}\")\n",
    "    \n",
    "    # Visualize performance metrics (saved as images)\n",
    "    ff.visualize_performance(performance_summary, airport_name, ff.OUTPUT_DIR)\n",
    "    \n",
    "    # Visualize predictions vs actuals (saved as images)\n",
    "    ff.visualize_predictions(results_clean, flights_per_year, airport_name, ff.OUTPUT_DIR)\n",
    "    \n",
    "    # -----------------------------------------------\n",
    "    # **Enhanced Line Plot with Actuals and 2025 Forecast**\n",
    "    # -----------------------------------------------\n",
    "    \n",
    "    # 1. Line Plot with Forecasts (Inline)\n",
    "    plt.figure(figsize=(14,8))\n",
    "    \n",
    "    # Plot Actuals with a distinct color and thicker line\n",
    "    plt.plot(\n",
    "        flights_per_year['Year'], \n",
    "        flights_per_year['Number_of_Flights'], \n",
    "        label='Actual', \n",
    "        marker='o', \n",
    "        color='black', \n",
    "        linewidth=2\n",
    "    )\n",
    "    \n",
    "    # Plot Predictions for each model\n",
    "    models = results_clean['Model'].unique()\n",
    "    \n",
    "    for model in models:\n",
    "        model_predictions = results_clean[results_clean['Model'] == model][['Year', 'Predicted']]\n",
    "        plt.plot(\n",
    "            model_predictions['Year'], \n",
    "            model_predictions['Predicted'], \n",
    "            label=model, \n",
    "            marker='o', \n",
    "            linewidth=1\n",
    "        )\n",
    "    \n",
    "    # Plot 2025 Forecast from the Best Model\n",
    "    if not np.isnan(prediction_2025):\n",
    "        plt.plot(\n",
    "            2025, \n",
    "            prediction_2025, \n",
    "            label='2025 Forecast', \n",
    "            marker='X', \n",
    "            markersize=12, \n",
    "            linestyle='--', \n",
    "            color='red'\n",
    "        )\n",
    "        plt.annotate(\n",
    "            '2025 Forecast', \n",
    "            xy=(2025, prediction_2025), \n",
    "            xytext=(2025, prediction_2025 + (0.05 * prediction_2025)),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05), \n",
    "            horizontalalignment='center'\n",
    "        )\n",
    "    \n",
    "    plt.title(f'Forecasted vs Actual Number of Flights in June for {airport_name}', fontsize=16)\n",
    "    plt.xlabel('Year', fontsize=14)\n",
    "    plt.ylabel('Number of Flights', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Display RMSE and MAE in a Table\n",
    "    print(\"Model Performance Summary:\")\n",
    "    display(performance_summary)\n",
    "    \n",
    "    # -----------------------------------------------\n",
    "    # **Optional: Display Separator**\n",
    "    # -----------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# After the loop, compile the prediction_summary list into a DataFrame\n",
    "summary_df = pd.DataFrame(prediction_summary)\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\n=== 2025 Flight Predictions Summary ===\")\n",
    "display(summary_df)\n",
    "\n",
    "# Define the path to save the summary table\n",
    "summary_table_path = os.path.join(ff.OUTPUT_DIR, '2025_Flight_Predictions_Summary.csv')\n",
    "\n",
    "# Save the summary DataFrame to CSV\n",
    "summary_df.to_csv(summary_table_path, index=False)\n",
    "print(f\"\\nSummary table saved to {summary_table_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
